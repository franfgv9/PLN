{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franfgv9/PLN/blob/main/practica4_pln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Apartado 1.1 — Instruções\n",
        "\n",
        "📘 Objetivo:\n",
        "Configurar el entorno de trabajo para usar NLTK y los corpus en portugués.\n",
        "\n",
        "📋 Pasos explicados:\n",
        "\n",
        "Instalar la biblioteca NLTK si aún no la tienes.\n",
        "\n",
        "Usar un entorno local o Google Colab.\n",
        "\n",
        "Descargar los corpus floresta y mac_morpho, que contienen frases en portugués ya etiquetadas y tokenizadas."
      ],
      "metadata": {
        "id": "k4v-yr5fVFRJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lSTUIGeUwvF",
        "outputId": "10140205-8c14-469f-9001-dd2182c1ca60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n",
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Package mac_morpho is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de frases en el corpus: 9266\n",
            "Ejemplo de frase tokenizada: ['Um', 'revivalismo', 'refrescante']\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Apartado 1.1: Instruções\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Instalar NLTK (solo si no lo tienes)\n",
        "!pip install nltk\n",
        "\n",
        "# Importar la librería\n",
        "import nltk\n",
        "\n",
        "# Descargar los corpus recomendados\n",
        "nltk.download('floresta')\n",
        "nltk.download('mac_morpho')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Comprobar carga del corpus floresta\n",
        "from nltk.corpus import floresta\n",
        "\n",
        "# Mostrar algunas frases de ejemplo\n",
        "sents = floresta.sents()\n",
        "print(\"Número de frases en el corpus:\", len(sents))\n",
        "print(\"Ejemplo de frase tokenizada:\", sents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Apartado 1.2 — Exemplo 1.1: Obtenção de n-gramas\n",
        "\n",
        "📘 Objetivo:\n",
        "Aprender a obtener bigramas, trigramas y n-gramas generales a partir de un corpus de texto."
      ],
      "metadata": {
        "id": "jJ3uYvPaV1SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Apartado 1.2: Exemplo 1.1\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "from nltk.corpus import floresta\n",
        "from nltk import bigrams, trigrams, ngrams, everygrams\n",
        "\n",
        "# Cargar frases del corpus floresta\n",
        "sents = floresta.sents()\n",
        "\n",
        "# Convertir todas las palabras a minúsculas\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "print(lowered_sents[:2])          # me devuelve las dos primeras frases ya tokanizadas (2 listas de palabras que forman cada frase)\n",
        "print(len(lowered_sents))\n",
        "\n",
        "# Ejemplo: obtener bigramas (pares de palabras)\n",
        "bi_grams = bigrams(lowered_sents[2])\n",
        "print(\"🔹 Bigramas:\")\n",
        "print(list(bi_grams))\n",
        "\n",
        "# Obtener trigramas (secuencias de tres palabras)\n",
        "tri_grams = trigrams(lowered_sents[3])\n",
        "print(\"\\n🔹 Trigramas:\")\n",
        "print(list(tri_grams))\n",
        "\n",
        "# Obtener pentagramas (n=5)\n",
        "pentagrams = ngrams(lowered_sents[3], n=5)\n",
        "print(\"\\n🔹 N-gramas de 5 palabras:\")\n",
        "print(list(pentagrams))\n",
        "\n",
        "# Obtener todos los n-gramas de hasta 3 palabras\n",
        "allgrams = everygrams(lowered_sents[3], max_len=3)\n",
        "print(\"\\n🔹 Todos los n-gramas hasta tamaño 3:\")\n",
        "print(list(allgrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BKwXKCNV19d",
        "outputId": "4482a7ff-c16e-40f6-842e-a6916f06086c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['um', 'revivalismo', 'refrescante'], ['o', '7_e_meio', 'é', 'um', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.']]\n",
            "9266\n",
            "🔹 Bigramas:\n",
            "[('é', 'uma'), ('uma', 'de'), ('de', 'as'), ('as', 'mais'), ('mais', 'antigas'), ('antigas', 'discotecas'), ('discotecas', 'de'), ('de', 'o'), ('o', 'algarve'), ('algarve', ','), (',', 'situada'), ('situada', 'em'), ('em', 'albufeira'), ('albufeira', ','), (',', 'que'), ('que', 'continua'), ('continua', 'a'), ('a', 'manter'), ('manter', 'os'), ('os', 'traços'), ('traços', 'decorativos'), ('decorativos', 'e'), ('e', 'as'), ('as', 'clientelas'), ('clientelas', 'de'), ('de', 'sempre'), ('sempre', '.')]\n",
            "\n",
            "🔹 Trigramas:\n",
            "[('é', 'um_pouco', 'a'), ('um_pouco', 'a', 'versão'), ('a', 'versão', 'de'), ('versão', 'de', 'uma'), ('de', 'uma', 'espécie'), ('uma', 'espécie', 'de'), ('espécie', 'de', '«'), ('de', '«', 'outro'), ('«', 'outro', 'lado'), ('outro', 'lado', 'de'), ('lado', 'de', 'a'), ('de', 'a', 'noite'), ('a', 'noite', ','), ('noite', ',', 'a'), (',', 'a', 'meio'), ('a', 'meio', 'caminho'), ('meio', 'caminho', 'entre'), ('caminho', 'entre', 'os'), ('entre', 'os', 'devaneios'), ('os', 'devaneios', 'de'), ('devaneios', 'de', 'uma'), ('de', 'uma', 'fauna'), ('uma', 'fauna', 'periférica'), ('fauna', 'periférica', ','), ('periférica', ',', 'seja'), (',', 'seja', 'de'), ('seja', 'de', 'lisboa'), ('de', 'lisboa', ','), ('lisboa', ',', 'londres'), (',', 'londres', ','), ('londres', ',', 'dublin'), (',', 'dublin', 'ou'), ('dublin', 'ou', 'faro'), ('ou', 'faro', 'e'), ('faro', 'e', 'portimão'), ('e', 'portimão', ','), ('portimão', ',', 'e'), (',', 'e', 'a'), ('e', 'a', 'postura'), ('a', 'postura', 'circunspecta'), ('postura', 'circunspecta', 'de'), ('circunspecta', 'de', 'os'), ('de', 'os', 'fiéis'), ('os', 'fiéis', 'de'), ('fiéis', 'de', 'a'), ('de', 'a', 'casa'), ('a', 'casa', ','), ('casa', ',', 'que'), (',', 'que', 'de'), ('que', 'de', 'ela'), ('de', 'ela', 'esperam'), ('ela', 'esperam', 'a'), ('esperam', 'a', 'música'), ('a', 'música', '«'), ('música', '«', 'geracionista'), ('«', 'geracionista', 'de'), ('geracionista', 'de', 'os'), ('de', 'os', '60'), ('os', '60', 'ou'), ('60', 'ou', 'de'), ('ou', 'de', 'os'), ('de', 'os', '70'), ('os', '70', '.')]\n",
            "\n",
            "🔹 N-gramas de 5 palabras:\n",
            "[('é', 'um_pouco', 'a', 'versão', 'de'), ('um_pouco', 'a', 'versão', 'de', 'uma'), ('a', 'versão', 'de', 'uma', 'espécie'), ('versão', 'de', 'uma', 'espécie', 'de'), ('de', 'uma', 'espécie', 'de', '«'), ('uma', 'espécie', 'de', '«', 'outro'), ('espécie', 'de', '«', 'outro', 'lado'), ('de', '«', 'outro', 'lado', 'de'), ('«', 'outro', 'lado', 'de', 'a'), ('outro', 'lado', 'de', 'a', 'noite'), ('lado', 'de', 'a', 'noite', ','), ('de', 'a', 'noite', ',', 'a'), ('a', 'noite', ',', 'a', 'meio'), ('noite', ',', 'a', 'meio', 'caminho'), (',', 'a', 'meio', 'caminho', 'entre'), ('a', 'meio', 'caminho', 'entre', 'os'), ('meio', 'caminho', 'entre', 'os', 'devaneios'), ('caminho', 'entre', 'os', 'devaneios', 'de'), ('entre', 'os', 'devaneios', 'de', 'uma'), ('os', 'devaneios', 'de', 'uma', 'fauna'), ('devaneios', 'de', 'uma', 'fauna', 'periférica'), ('de', 'uma', 'fauna', 'periférica', ','), ('uma', 'fauna', 'periférica', ',', 'seja'), ('fauna', 'periférica', ',', 'seja', 'de'), ('periférica', ',', 'seja', 'de', 'lisboa'), (',', 'seja', 'de', 'lisboa', ','), ('seja', 'de', 'lisboa', ',', 'londres'), ('de', 'lisboa', ',', 'londres', ','), ('lisboa', ',', 'londres', ',', 'dublin'), (',', 'londres', ',', 'dublin', 'ou'), ('londres', ',', 'dublin', 'ou', 'faro'), (',', 'dublin', 'ou', 'faro', 'e'), ('dublin', 'ou', 'faro', 'e', 'portimão'), ('ou', 'faro', 'e', 'portimão', ','), ('faro', 'e', 'portimão', ',', 'e'), ('e', 'portimão', ',', 'e', 'a'), ('portimão', ',', 'e', 'a', 'postura'), (',', 'e', 'a', 'postura', 'circunspecta'), ('e', 'a', 'postura', 'circunspecta', 'de'), ('a', 'postura', 'circunspecta', 'de', 'os'), ('postura', 'circunspecta', 'de', 'os', 'fiéis'), ('circunspecta', 'de', 'os', 'fiéis', 'de'), ('de', 'os', 'fiéis', 'de', 'a'), ('os', 'fiéis', 'de', 'a', 'casa'), ('fiéis', 'de', 'a', 'casa', ','), ('de', 'a', 'casa', ',', 'que'), ('a', 'casa', ',', 'que', 'de'), ('casa', ',', 'que', 'de', 'ela'), (',', 'que', 'de', 'ela', 'esperam'), ('que', 'de', 'ela', 'esperam', 'a'), ('de', 'ela', 'esperam', 'a', 'música'), ('ela', 'esperam', 'a', 'música', '«'), ('esperam', 'a', 'música', '«', 'geracionista'), ('a', 'música', '«', 'geracionista', 'de'), ('música', '«', 'geracionista', 'de', 'os'), ('«', 'geracionista', 'de', 'os', '60'), ('geracionista', 'de', 'os', '60', 'ou'), ('de', 'os', '60', 'ou', 'de'), ('os', '60', 'ou', 'de', 'os'), ('60', 'ou', 'de', 'os', '70'), ('ou', 'de', 'os', '70', '.')]\n",
            "\n",
            "🔹 Todos los n-gramas hasta tamaño 3:\n",
            "[('é',), ('é', 'um_pouco'), ('é', 'um_pouco', 'a'), ('um_pouco',), ('um_pouco', 'a'), ('um_pouco', 'a', 'versão'), ('a',), ('a', 'versão'), ('a', 'versão', 'de'), ('versão',), ('versão', 'de'), ('versão', 'de', 'uma'), ('de',), ('de', 'uma'), ('de', 'uma', 'espécie'), ('uma',), ('uma', 'espécie'), ('uma', 'espécie', 'de'), ('espécie',), ('espécie', 'de'), ('espécie', 'de', '«'), ('de',), ('de', '«'), ('de', '«', 'outro'), ('«',), ('«', 'outro'), ('«', 'outro', 'lado'), ('outro',), ('outro', 'lado'), ('outro', 'lado', 'de'), ('lado',), ('lado', 'de'), ('lado', 'de', 'a'), ('de',), ('de', 'a'), ('de', 'a', 'noite'), ('a',), ('a', 'noite'), ('a', 'noite', ','), ('noite',), ('noite', ','), ('noite', ',', 'a'), (',',), (',', 'a'), (',', 'a', 'meio'), ('a',), ('a', 'meio'), ('a', 'meio', 'caminho'), ('meio',), ('meio', 'caminho'), ('meio', 'caminho', 'entre'), ('caminho',), ('caminho', 'entre'), ('caminho', 'entre', 'os'), ('entre',), ('entre', 'os'), ('entre', 'os', 'devaneios'), ('os',), ('os', 'devaneios'), ('os', 'devaneios', 'de'), ('devaneios',), ('devaneios', 'de'), ('devaneios', 'de', 'uma'), ('de',), ('de', 'uma'), ('de', 'uma', 'fauna'), ('uma',), ('uma', 'fauna'), ('uma', 'fauna', 'periférica'), ('fauna',), ('fauna', 'periférica'), ('fauna', 'periférica', ','), ('periférica',), ('periférica', ','), ('periférica', ',', 'seja'), (',',), (',', 'seja'), (',', 'seja', 'de'), ('seja',), ('seja', 'de'), ('seja', 'de', 'lisboa'), ('de',), ('de', 'lisboa'), ('de', 'lisboa', ','), ('lisboa',), ('lisboa', ','), ('lisboa', ',', 'londres'), (',',), (',', 'londres'), (',', 'londres', ','), ('londres',), ('londres', ','), ('londres', ',', 'dublin'), (',',), (',', 'dublin'), (',', 'dublin', 'ou'), ('dublin',), ('dublin', 'ou'), ('dublin', 'ou', 'faro'), ('ou',), ('ou', 'faro'), ('ou', 'faro', 'e'), ('faro',), ('faro', 'e'), ('faro', 'e', 'portimão'), ('e',), ('e', 'portimão'), ('e', 'portimão', ','), ('portimão',), ('portimão', ','), ('portimão', ',', 'e'), (',',), (',', 'e'), (',', 'e', 'a'), ('e',), ('e', 'a'), ('e', 'a', 'postura'), ('a',), ('a', 'postura'), ('a', 'postura', 'circunspecta'), ('postura',), ('postura', 'circunspecta'), ('postura', 'circunspecta', 'de'), ('circunspecta',), ('circunspecta', 'de'), ('circunspecta', 'de', 'os'), ('de',), ('de', 'os'), ('de', 'os', 'fiéis'), ('os',), ('os', 'fiéis'), ('os', 'fiéis', 'de'), ('fiéis',), ('fiéis', 'de'), ('fiéis', 'de', 'a'), ('de',), ('de', 'a'), ('de', 'a', 'casa'), ('a',), ('a', 'casa'), ('a', 'casa', ','), ('casa',), ('casa', ','), ('casa', ',', 'que'), (',',), (',', 'que'), (',', 'que', 'de'), ('que',), ('que', 'de'), ('que', 'de', 'ela'), ('de',), ('de', 'ela'), ('de', 'ela', 'esperam'), ('ela',), ('ela', 'esperam'), ('ela', 'esperam', 'a'), ('esperam',), ('esperam', 'a'), ('esperam', 'a', 'música'), ('a',), ('a', 'música'), ('a', 'música', '«'), ('música',), ('música', '«'), ('música', '«', 'geracionista'), ('«',), ('«', 'geracionista'), ('«', 'geracionista', 'de'), ('geracionista',), ('geracionista', 'de'), ('geracionista', 'de', 'os'), ('de',), ('de', 'os'), ('de', 'os', '60'), ('os',), ('os', '60'), ('os', '60', 'ou'), ('60',), ('60', 'ou'), ('60', 'ou', 'de'), ('ou',), ('ou', 'de'), ('ou', 'de', 'os'), ('de',), ('de', 'os'), ('de', 'os', '70'), ('os',), ('os', '70'), ('os', '70', '.'), ('70',), ('70', '.'), ('.',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Apartado 1.2 — Exemplo 1.2: Distribuição de frequências\n",
        "\n",
        "📘 Objetivo:\n",
        "Calcular cuántas veces aparece cada n-grama en un texto o corpus y mostrar los más frecuentes."
      ],
      "metadata": {
        "id": "0a4m6P2xXqlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Apartado 1.2: Exemplo 1.2\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Frase de ejemplo\n",
        "proverbio = \"\"\"\n",
        "O tempo perguntou ao tempo quanto tempo o tempo tem;\n",
        "o tempo respondeu ao tempo que o tempo tem tanto tempo quanto tempo o tempo tem.\n",
        "\"\"\"\n",
        "\n",
        "# Import necessary functions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Tokenizar la frase y pasar todo a minúsculas\n",
        "tokens = word_tokenize(proverbio.lower())\n",
        "\n",
        "# Generar bigramas\n",
        "bigrams_list = list(nltk.bigrams(tokens))\n",
        "\n",
        "# Calcular la distribución de frecuencias\n",
        "ngram_fdist = FreqDist(bigrams_list)\n",
        "\n",
        "# Mostrar los 10 bigramas más frecuentes\n",
        "print(\"🔹 Bigramas más frecuentes:\")\n",
        "for bigrama, freq in ngram_fdist.most_common(10):\n",
        "    print(f\"{bigrama}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R8QrmkXXxvJ",
        "outputId": "6b927039-fb11-434f-e74c-d5bd31c497c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Bigramas más frecuentes:\n",
            "('o', 'tempo'): 5\n",
            "('tempo', 'tem'): 3\n",
            "('ao', 'tempo'): 2\n",
            "('tempo', 'quanto'): 2\n",
            "('quanto', 'tempo'): 2\n",
            "('tempo', 'o'): 2\n",
            "('tempo', 'perguntou'): 1\n",
            "('perguntou', 'ao'): 1\n",
            "('tem', ';'): 1\n",
            "(';', 'o'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Exercício 1.1 — N-gramas mais frequentes\n",
        "\n",
        "📘 Enunciado resumido:\n",
        "\n",
        "Crea una función que reciba una lista de frases (por ejemplo, del corpus floresta) y devuelva los m n-gramas más frecuentes, dentro de un intervalo de n que elijas.\n",
        "\n",
        "💡 Además, el enunciado sugiere usar el método update() de FreqDist para ir actualizando las frecuencias de varios tamaños de n-gramas."
      ],
      "metadata": {
        "id": "oLvqM9jDYzXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exercício 1.1\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk import everygrams, FreqDist\n",
        "\n",
        "# Cargar frases y pasarlas a minúsculas\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "def ngramas_mas_frecuentes(sentences, min_n=2, max_n=3, m=10):\n",
        "    \"\"\"\n",
        "    Calcula los m n-gramas más frecuentes en una lista de frases.\n",
        "\n",
        "    Parámetros:\n",
        "    - sentences: lista de frases tokenizadas.\n",
        "    - min_n, max_n: intervalo del tamaño de los n-gramas (por defecto 2 a 3).\n",
        "    - m: número de n-gramas más frecuentes a mostrar.\n",
        "    \"\"\"\n",
        "    fdist = FreqDist()\n",
        "\n",
        "    # Recorremos cada frase\n",
        "    for sent in sentences:\n",
        "        # Generar todos los n-gramas entre min_n y max_n\n",
        "        ngram_list = everygrams(sent, min_len=min_n, max_len=max_n)\n",
        "        # Actualizar el contador de frecuencias\n",
        "        fdist.update(ngram_list)\n",
        "\n",
        "    # Mostrar los m más comunes\n",
        "    print(f\"🔹 {m} n-gramas más frecuentes (entre {min_n} y {max_n}):\")\n",
        "    for ngram, freq in fdist.most_common(m):\n",
        "        print(f\"{ngram}: {freq}\")\n",
        "\n",
        "    return fdist.most_common(m)\n",
        "\n",
        "# Ejecutar función con los parámetros por defecto\n",
        "ngramas_mas_frecuentes(lowered_sents, min_n=2, max_n=3, m=10)\n",
        "\n",
        "\n",
        "# FALTARÍA CREAR OTRA FUNCION QUE ELIMINE STOPWORDS Y ACENTUACIONES (una frase foto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTZCIsROY0VV",
        "outputId": "d9ad3961-fb48-445e-cd4e-4db75de17b81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 10 n-gramas más frecuentes (entre 2 y 3):\n",
            "('de', 'o'): 2876\n",
            "('de', 'a'): 2567\n",
            "('em', 'o'): 1511\n",
            "('em', 'a'): 1402\n",
            "('de', 'os'): 1003\n",
            "(',', 'em'): 826\n",
            "('»', ','): 758\n",
            "(',', 'a'): 745\n",
            "('a', 'o'): 742\n",
            "(',', 'que'): 676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('de', 'o'), 2876),\n",
              " (('de', 'a'), 2567),\n",
              " (('em', 'o'), 1511),\n",
              " (('em', 'a'), 1402),\n",
              " (('de', 'os'), 1003),\n",
              " ((',', 'em'), 826),\n",
              " (('»', ','), 758),\n",
              " ((',', 'a'), 745),\n",
              " (('a', 'o'), 742),\n",
              " ((',', 'que'), 676)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Exemplo 1.3 — Marcando el início e o fim das frases\n",
        "\n",
        "📘 Objetivo:\n",
        "Aprender a preparar los datos para entrenar modelos de lenguaje, añadiendo marcadores de inicio (<s>) y fin (</s>) a cada frase."
      ],
      "metadata": {
        "id": "mScSuvkKaJp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 ¿Por qué se hace esto?\n",
        "\n",
        "Cuando entrenamos modelos de lenguaje (por ejemplo, de bigramas o trigramas), queremos que el modelo entienda cuándo empieza y cuándo termina una frase.\n",
        "Así puede aprender cosas como:\n",
        "\n",
        "Qué palabras suelen comenzar una oración.\n",
        "\n",
        "Qué palabras suelen aparecer al final.\n",
        "\n",
        "IMPORTANTE: pero todo esto esta relacionado con los diagramas, para que no se invente n-gramas cambiandole el orden a las palabras porque sabe que las que lleven \"s\" es porque es la palabra de inicio y no puede ir en el medio ni en el final"
      ],
      "metadata": {
        "id": "0IHahCW4am6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.3\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
        "\n",
        "# Asegurar que el corpus esté descargado\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Cargar y preparar las frases\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# Ejemplo con una frase concreta\n",
        "tokens = lowered_sents[0]\n",
        "\n",
        "# 🔹 Añadir marcadores de inicio y fin manualmente\n",
        "padded_tokens = list(pad_both_ends(tokens, n=2))\n",
        "print(\"🔸 Tokens con padding:\")\n",
        "print(padded_tokens)\n",
        "\n",
        "# 🔹 Generar bigramas a partir de la frase con padding\n",
        "padded_bigrams = list(nltk.bigrams(padded_tokens))\n",
        "print(\"\\n🔸 Bigramas con padding:\")\n",
        "print(padded_bigrams)\n",
        "\n",
        "# 🔹 Alternativa: hacer lo mismo para todas las frases del corpus\n",
        "data, vocab = padded_everygram_pipeline(2, lowered_sents)\n",
        "vocab = list(vocab)\n",
        "\n",
        "print(\"\\n🔸 Ejemplo de n-gramas generados:\")\n",
        "for sent in data:\n",
        "    for ngram in sent:\n",
        "        print(ngram)\n",
        "    break  # mostramos solo la primera frase\n",
        "\n",
        "print(\"\\n🔸 Vocabulario (primeras 50 palabras):\")\n",
        "print(vocab[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3DHtaFgauF0",
        "outputId": "3c720944-f281-467c-edcf-772f9bfd94a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔸 Tokens con padding:\n",
            "['<s>', 'um', 'revivalismo', 'refrescante', '</s>']\n",
            "\n",
            "🔸 Bigramas con padding:\n",
            "[('<s>', 'um'), ('um', 'revivalismo'), ('revivalismo', 'refrescante'), ('refrescante', '</s>')]\n",
            "\n",
            "🔸 Ejemplo de n-gramas generados:\n",
            "('<s>',)\n",
            "('<s>', 'um')\n",
            "('um',)\n",
            "('um', 'revivalismo')\n",
            "('revivalismo',)\n",
            "('revivalismo', 'refrescante')\n",
            "('refrescante',)\n",
            "('refrescante', '</s>')\n",
            "('</s>',)\n",
            "\n",
            "🔸 Vocabulario (primeras 50 palabras):\n",
            "['<s>', 'um', 'revivalismo', 'refrescante', '</s>', '<s>', 'o', '7_e_meio', 'é', 'um', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.', '</s>', '<s>', 'é', 'uma', 'de', 'as', 'mais', 'antigas', 'discotecas', 'de', 'o', 'algarve', ',', 'situada', 'em', 'albufeira', ',', 'que', 'continua', 'a', 'manter', 'os', 'traços', 'decorativos', 'e', 'as', 'clientelas', 'de', 'sempre', '.', '</s>', '<s>', 'é', 'um_pouco']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔮 Cómo ayuda en la práctica\n",
        "\n",
        "1️⃣ En entrenamiento de modelos de lenguaje\n",
        "Cuando entrenas un modelo (por ejemplo, MLE(2) de NLTK), el padding permite calcular probabilidades como:\n",
        "\n",
        "P(\"o\" | \"s\") → qué palabra suele venir al comienzo.\n",
        "P(\"/s\" | \"tempo\") → qué palabra suele venir al final.\n",
        "\n",
        "2️⃣ En generación de texto\n",
        "Cuando generas nuevas frases, el modelo empieza desde s y sigue eligiendo palabras hasta que llega a /s.\n",
        "Así sabe dónde empezar y dónde detenerse.\n",
        "\n",
        "3️⃣ En evaluación del modelo (perplejidad)\n",
        "Durante la evaluación con frases de prueba, también se usan los marcadores para mantener la coherencia del cálculo de probabilidad total de una oración."
      ],
      "metadata": {
        "id": "HFg1PlUvc4cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Exemplo 1.4 — Treinar um modelo de bi-gramas (MLE)\n",
        "\n",
        "📘 Objetivo:\n",
        "Aprender a entrenar un modelo de lenguaje de n-gramas utilizando la clase MLE (Maximum Likelihood Estimator) de la biblioteca NLTK.\n",
        "\n",
        "🧠 Qué es un modelo de lenguaje basado en n-gramas\n",
        "\n",
        "Un modelo de lenguaje intenta predecir la siguiente palabra a partir de las anteriores.\n",
        "En un modelo de bigramas (n = 2), se calcula la probabilidad de cada palabra según la anterior:"
      ],
      "metadata": {
        "id": "dmBMfIT_dJlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "P(w_i \\mid w_{i-1}) = \\frac{C(w_{i-1}, w_i)}{C(w_{i-1})}\n",
        "$$\n",
        "\n",
        "donde:  \n",
        "\n",
        "- \\( C(w_{i-1}, w_i) \\) = cuántas veces aparece el bigrama  \n",
        "- \\( C(w_{i-1}) \\) = cuántas veces aparece la primera palabra del bigrama\n"
      ],
      "metadata": {
        "id": "a4zNioEUeSiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.4\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar corpus\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Cargar frases y convertirlas a minúsculas\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# 🔹 Preparar datos con padding y obtener vocabulario\n",
        "n = 2  # modelo de bigramas\n",
        "train_data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "# 🔹 Crear el modelo MLE (Maximum Likelihood Estimation)\n",
        "lm = MLE(n)\n",
        "\n",
        "# 🔹 Entrenar el modelo con los datos\n",
        "lm.fit(train_data, vocab)\n",
        "\n",
        "# 🔹 Mostrar tamaño del vocabulario aprendido\n",
        "print(\"🔹 Tamaño del vocabulario:\", len(lm.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsSes7-PdouF",
        "outputId": "094b522d-97e3-4852-c420-28a54ebbb6ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Tamaño del vocabulario: 27717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCLUSION: Para entender como funciona realmente el padding en los n-gramas y usa el modelo el MLE para predecir la sigueinte palabra.\n",
        "# 🔍 Qué hace internamente el modelo\n",
        "  # Aprende cuántas veces aparece cada bigrama en el corpus.\n",
        "  # Calcula la probabilidad condicional de una palabra dada la anterior.\n",
        "  # Usa <s> y </s> para entender los límites de frases."
      ],
      "metadata": {
        "id": "4vi46o1Kd8X6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Exemplo 1.5 — Consultar el modelo MLE"
      ],
      "metadata": {
        "id": "DqUuXTakePUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 Objetivo:\n",
        "Aprender a:\n",
        "\n",
        "Buscar palabras o secuencias dentro del vocabulario del modelo.\n",
        "\n",
        "Consultar cuántas veces aparecen ciertos bigramas.\n",
        "\n",
        "Calcular probabilidades según el modelo entrenado."
      ],
      "metadata": {
        "id": "OpizDwMyednI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Conceptos importantes\n",
        "\n",
        "1️⃣ Vocabulario del modelo (lm.vocab)\n",
        "Incluye todas las palabras que el modelo ha visto durante el entrenamiento.\n",
        "Las palabras no vistas se representan con el símbolo <UNK> (unknown token).\n",
        "\n",
        "2️⃣ Conteos (lm.counts)\n",
        "El modelo almacena las frecuencias de todos los unigramas, bigramas, etc.\n",
        "Puedes acceder a ellas como si fuera un diccionario anidado:\n",
        "\n",
        "lm.counts['palabra']              # cuántas veces aparece la palabra\n",
        "lm.counts[['palabra']]['otra']    # cuántas veces aparece ('palabra', 'otra')\n",
        "\n",
        "\n",
        "3️⃣ Probabilidades (lm.score())\n",
        "Calcula la probabilidad condicional de una palabra dada el contexto previo:\n",
        "\n",
        "lm.score('dia', ['de'])  # P('dia' | 'de')"
      ],
      "metadata": {
        "id": "0auXrjYaey4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.5\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar corpus\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Preparar corpus\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# Preparar datos y vocabulario (bigramas)\n",
        "n = 2\n",
        "data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "# Entrenar el modelo\n",
        "lm = MLE(n)\n",
        "lm.fit(data, vocab)\n",
        "\n",
        "# 🔹 Consultar el vocabulario\n",
        "print(\"🔹 Vocabulario (primeras 20 palabras):\")\n",
        "print(list(lm.vocab)[:20])\n",
        "\n",
        "# 🔹 Buscar secuencias en el modelo\n",
        "print(\"\\n🔹 Lookup de frases conocidas y desconocidas:\")\n",
        "print(lm.vocab.lookup(lowered_sents[0]))\n",
        "print(lm.vocab.lookup(['isto', 'é', 'um', 'teste']))\n",
        "print(lm.vocab.lookup(['uma', 'espécie', 'de', 'blah']))\n",
        "\n",
        "# 🔹 Consultar contajes (frecuencias)\n",
        "print(\"\\n🔹 Conteos:\")\n",
        "print(\"C('dois') =\", lm.counts['dois'])\n",
        "print(\"C('dois', 'anos') =\", lm.counts[['dois']]['anos'])\n",
        "print(\"C('dois', 'dias') =\", lm.counts[['dois']]['dias'])\n",
        "\n",
        "# 🔹 Consultar probabilidades\n",
        "print(\"\\n🔹 Probabilidades según el modelo:\")\n",
        "print(\"P('noite') =\", lm.score('noite'))\n",
        "print(\"P('dia' | 'de') =\", lm.score('dia', ['de']))      # la prob de aparecer dia despues de \"de\"\n",
        "print(\"P('de' | 'tarde') =\", lm.score('de', ['tarde']))\n",
        "print(\"P('de' | 'noite') =\", lm.score('de', ['noite']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP2RVCXJe7AB",
        "outputId": "a9545e80-db14-4cf1-e558-d536966bd3d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Vocabulario (primeras 20 palabras):\n",
            "['<s>', 'um', 'revivalismo', 'refrescante', '</s>', 'o', '7_e_meio', 'é', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.', 'uma', 'as', 'mais', 'antigas', 'discotecas', 'algarve']\n",
            "\n",
            "🔹 Lookup de frases conocidas y desconocidas:\n",
            "('um', 'revivalismo', 'refrescante')\n",
            "('isto', 'é', 'um', 'teste')\n",
            "('uma', 'espécie', 'de', '<UNK>')\n",
            "\n",
            "🔹 Conteos:\n",
            "C('dois') = 231\n",
            "C('dois', 'anos') = 14\n",
            "C('dois', 'dias') = 12\n",
            "\n",
            "🔹 Probabilidades según el modelo:\n",
            "P('noite') = 0.0002647753316202514\n",
            "P('dia' | 'de') = 0.00013630477748245075\n",
            "P('de' | 'tarde') = 0.18518518518518517\n",
            "P('de' | 'noite') = 0.2786885245901639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Exemplo 1.6 — Geração de texto com o modelo MLE"
      ],
      "metadata": {
        "id": "7OE5WM8gI_86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 Objetivo:\n",
        "Usar el modelo de lenguaje entrenado (en el Exemplo 1.4) para generar secuencias de palabras nuevas que imiten el estilo del corpus."
      ],
      "metadata": {
        "id": "OgC-Iq_lI8mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.6\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar corpus\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Preparar corpus\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# Preparar datos (bigramas)\n",
        "n = 2\n",
        "train_data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "# Entrenar modelo de bigramas\n",
        "lm = MLE(n)\n",
        "lm.fit(train_data, vocab)\n",
        "\n",
        "# 🔹 Generar una secuencia de 7 palabras\n",
        "print(\"🔹 Frase generada por el modelo:\\n\")\n",
        "print(lm.generate(7, random_seed=3))"
      ],
      "metadata": {
        "id": "pSYgnsY6JMO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c3e148-e73e-4a11-8429-65857f3629cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Frase generada por el modelo:\n",
            "\n",
            "['a', 'morte', 'de', 'o', 'paulistano', 'não', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Objetivo del Ejercicio 1.2"
      ],
      "metadata": {
        "id": "-EhnN0uVvWhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "“Experimente treinar modelos de n-gramas de diferentes tamanhos, com diferentes corpos, para depois gerar sequências com eles.”\n",
        "\n",
        "En otras palabras, debemos:\n",
        "\n",
        "Entrenar modelos de lenguaje basados en n-gramas (por ejemplo, unigramas, bigramas, trigramas).\n",
        "\n",
        "Probarlos con diferentes corpus (como floresta o mac_morpho del NLTK).\n",
        "\n",
        "Generar secuencias de texto con cada modelo para observar cómo cambia el resultado según el tamaño de los n-gramas y el corpus usado."
      ],
      "metadata": {
        "id": "OKyMYOJPvdg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Ejercicio 1.2 - Modelos de N-gramas\n",
        "# ==============================\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta, mac_morpho\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar que los corpus estén descargados\n",
        "nltk.download('floresta')\n",
        "nltk.download('mac_morpho')\n",
        "\n",
        "# Selección de corpus\n",
        "corpora = {\n",
        "    'floresta': floresta.sents(),\n",
        "    'mac_morpho': mac_morpho.sents()\n",
        "}\n",
        "\n",
        "# Función para entrenar modelo y generar texto\n",
        "def treinar_e_gerar(corpus, n=2, num_palavras=10):\n",
        "    # Convertir todas las palabras a minúsculas\n",
        "    lowered_sents = [[w.lower() for w in s] for s in corpus]\n",
        "\n",
        "    # Preparar datos y vocabulario\n",
        "    train_data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "    # Entrenar modelo MLE\n",
        "    model = MLE(n)\n",
        "    model.fit(train_data, vocab)\n",
        "\n",
        "    # Generar texto\n",
        "    print(f\"\\n=== Modelo {n}-gramas ({len(model.vocab)} palabras no repetidas) ===\")\n",
        "    print(\"Texto generado:\")\n",
        "    print(' '.join(model.generate(num_palavras, random_seed=3)))\n",
        "\n",
        "# Entrenar modelos con diferentes corpus y tamaños de n-gramas\n",
        "for nome_corpus, corpus in corpora.items():\n",
        "    print(f\"\\n\\n--- Corpus: {nome_corpus.upper()} ---\")\n",
        "    for n in [2, 3, 4]:\n",
        "        treinar_e_gerar(corpus, n=n, num_palavras=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_bA2bEnvesu",
        "outputId": "2688ac46-a955-4d35-b7b8-e353a1d3154a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n",
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Package mac_morpho is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Corpus: FLORESTA ---\n",
            "\n",
            "=== Modelo 2-gramas (27717 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "a morte de o paulistano não ? </s> afirmou a óscar_monteiro_torres ,\n",
            "\n",
            "=== Modelo 3-gramas (27717 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> a família durante o almoço de trabalho . </s> </s> </s>\n",
            "\n",
            "=== Modelo 4-gramas (27717 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> <s> <s> o papa joão_paulo_2º escolheu a irmã emília_ehrlich para ocupar\n",
            "\n",
            "\n",
            "--- Corpus: MAC_MORPHO ---\n",
            "\n",
            "=== Modelo 2-gramas (59914 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "a mesma equipe econômica e 80 % em a copa é menor\n",
            "\n",
            "=== Modelo 3-gramas (59914 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> a flórida </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "\n",
            "=== Modelo 4-gramas (59914 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> <s> <s> museu de arte contemporânea reúne 112 destacados artistas de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Objetivo del Ejercicio 1.3"
      ],
      "metadata": {
        "id": "zxFTUpP7xf5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "“Crie uma função para, a partir da lista de tokens geradas, que pode ainda incluir os símbolos <s> e </s>, crie uma única string. Pode ignorar os <s> e parar nos </s>, e também pode usar a função detokenize() da classe TreebankWordDetokenizer.”\n",
        "\n",
        "En este ejercicio debemos reconstruir una frase completa (string) a partir de una lista de tokens generada por un modelo de lenguaje.\n",
        "Durante la generación del texto, el modelo incluye los símbolos <s> (inicio de frase) y </s> (fin de frase).\n",
        "El objetivo es eliminar esos marcadores y unir los tokens en una frase limpia."
      ],
      "metadata": {
        "id": "vbP1b8L4xhnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Ejercicio 1.3 - Detokenización de secuencias\n",
        "# ==============================\n",
        "\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "def reconstruir_frase(tokens):\n",
        "    \"\"\"\n",
        "    Recibe una lista de tokens posiblemente con <s> y </s>,\n",
        "    ignora esos símbolos y devuelve una única string limpia.\n",
        "    \"\"\"\n",
        "    frase_tokens = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        elif token == '</s>':\n",
        "            break\n",
        "        frase_tokens.append(token)\n",
        "\n",
        "    # Usar TreebankWordDetokenizer para recomponer la frase\n",
        "    detok = TreebankWordDetokenizer().detokenize(frase_tokens)\n",
        "    return detok\n",
        "\n",
        "# Ejemplo de uso:\n",
        "tokens_gerados = ['<s>', 'o', 'tempo', 'voa', 'rápido', '</s>']\n",
        "frase = reconstruir_frase(tokens_gerados)\n",
        "print(\"Tokens:\", tokens_gerados)\n",
        "print(\"Frase reconstruida:\", frase)\n"
      ],
      "metadata": {
        "id": "FSntViX1wtha",
        "outputId": "84c9551d-8d6a-4a92-d727-7ce5cf040317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['<s>', 'o', 'tempo', 'voa', 'rápido', '</s>']\n",
            "Frase reconstruida: o tempo voa rápido\n"
          ]
        }
      ]
    }
  ]
}