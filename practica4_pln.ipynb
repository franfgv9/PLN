{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franfgv9/PLN/blob/main/practica4_pln.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Apartado 1.1 ‚Äî Instru√ß√µes\n",
        "\n",
        "üìò Objetivo:\n",
        "Configurar el entorno de trabajo para usar NLTK y los corpus en portugu√©s.\n",
        "\n",
        "üìã Pasos explicados:\n",
        "\n",
        "Instalar la biblioteca NLTK si a√∫n no la tienes.\n",
        "\n",
        "Usar un entorno local o Google Colab.\n",
        "\n",
        "Descargar los corpus floresta y mac_morpho, que contienen frases en portugu√©s ya etiquetadas y tokenizadas."
      ],
      "metadata": {
        "id": "k4v-yr5fVFRJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lSTUIGeUwvF",
        "outputId": "10140205-8c14-469f-9001-dd2182c1ca60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n",
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Package mac_morpho is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de frases en el corpus: 9266\n",
            "Ejemplo de frase tokenizada: ['Um', 'revivalismo', 'refrescante']\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Apartado 1.1: Instru√ß√µes\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Instalar NLTK (solo si no lo tienes)\n",
        "!pip install nltk\n",
        "\n",
        "# Importar la librer√≠a\n",
        "import nltk\n",
        "\n",
        "# Descargar los corpus recomendados\n",
        "nltk.download('floresta')\n",
        "nltk.download('mac_morpho')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Comprobar carga del corpus floresta\n",
        "from nltk.corpus import floresta\n",
        "\n",
        "# Mostrar algunas frases de ejemplo\n",
        "sents = floresta.sents()\n",
        "print(\"N√∫mero de frases en el corpus:\", len(sents))\n",
        "print(\"Ejemplo de frase tokenizada:\", sents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Apartado 1.2 ‚Äî Exemplo 1.1: Obten√ß√£o de n-gramas\n",
        "\n",
        "üìò Objetivo:\n",
        "Aprender a obtener bigramas, trigramas y n-gramas generales a partir de un corpus de texto."
      ],
      "metadata": {
        "id": "jJ3uYvPaV1SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Apartado 1.2: Exemplo 1.1\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "from nltk.corpus import floresta\n",
        "from nltk import bigrams, trigrams, ngrams, everygrams\n",
        "\n",
        "# Cargar frases del corpus floresta\n",
        "sents = floresta.sents()\n",
        "\n",
        "# Convertir todas las palabras a min√∫sculas\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "print(lowered_sents[:2])          # me devuelve las dos primeras frases ya tokanizadas (2 listas de palabras que forman cada frase)\n",
        "print(len(lowered_sents))\n",
        "\n",
        "# Ejemplo: obtener bigramas (pares de palabras)\n",
        "bi_grams = bigrams(lowered_sents[2])\n",
        "print(\"üîπ Bigramas:\")\n",
        "print(list(bi_grams))\n",
        "\n",
        "# Obtener trigramas (secuencias de tres palabras)\n",
        "tri_grams = trigrams(lowered_sents[3])\n",
        "print(\"\\nüîπ Trigramas:\")\n",
        "print(list(tri_grams))\n",
        "\n",
        "# Obtener pentagramas (n=5)\n",
        "pentagrams = ngrams(lowered_sents[3], n=5)\n",
        "print(\"\\nüîπ N-gramas de 5 palabras:\")\n",
        "print(list(pentagrams))\n",
        "\n",
        "# Obtener todos los n-gramas de hasta 3 palabras\n",
        "allgrams = everygrams(lowered_sents[3], max_len=3)\n",
        "print(\"\\nüîπ Todos los n-gramas hasta tama√±o 3:\")\n",
        "print(list(allgrams))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BKwXKCNV19d",
        "outputId": "4482a7ff-c16e-40f6-842e-a6916f06086c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['um', 'revivalismo', 'refrescante'], ['o', '7_e_meio', '√©', 'um', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.']]\n",
            "9266\n",
            "üîπ Bigramas:\n",
            "[('√©', 'uma'), ('uma', 'de'), ('de', 'as'), ('as', 'mais'), ('mais', 'antigas'), ('antigas', 'discotecas'), ('discotecas', 'de'), ('de', 'o'), ('o', 'algarve'), ('algarve', ','), (',', 'situada'), ('situada', 'em'), ('em', 'albufeira'), ('albufeira', ','), (',', 'que'), ('que', 'continua'), ('continua', 'a'), ('a', 'manter'), ('manter', 'os'), ('os', 'tra√ßos'), ('tra√ßos', 'decorativos'), ('decorativos', 'e'), ('e', 'as'), ('as', 'clientelas'), ('clientelas', 'de'), ('de', 'sempre'), ('sempre', '.')]\n",
            "\n",
            "üîπ Trigramas:\n",
            "[('√©', 'um_pouco', 'a'), ('um_pouco', 'a', 'vers√£o'), ('a', 'vers√£o', 'de'), ('vers√£o', 'de', 'uma'), ('de', 'uma', 'esp√©cie'), ('uma', 'esp√©cie', 'de'), ('esp√©cie', 'de', '¬´'), ('de', '¬´', 'outro'), ('¬´', 'outro', 'lado'), ('outro', 'lado', 'de'), ('lado', 'de', 'a'), ('de', 'a', 'noite'), ('a', 'noite', ','), ('noite', ',', 'a'), (',', 'a', 'meio'), ('a', 'meio', 'caminho'), ('meio', 'caminho', 'entre'), ('caminho', 'entre', 'os'), ('entre', 'os', 'devaneios'), ('os', 'devaneios', 'de'), ('devaneios', 'de', 'uma'), ('de', 'uma', 'fauna'), ('uma', 'fauna', 'perif√©rica'), ('fauna', 'perif√©rica', ','), ('perif√©rica', ',', 'seja'), (',', 'seja', 'de'), ('seja', 'de', 'lisboa'), ('de', 'lisboa', ','), ('lisboa', ',', 'londres'), (',', 'londres', ','), ('londres', ',', 'dublin'), (',', 'dublin', 'ou'), ('dublin', 'ou', 'faro'), ('ou', 'faro', 'e'), ('faro', 'e', 'portim√£o'), ('e', 'portim√£o', ','), ('portim√£o', ',', 'e'), (',', 'e', 'a'), ('e', 'a', 'postura'), ('a', 'postura', 'circunspecta'), ('postura', 'circunspecta', 'de'), ('circunspecta', 'de', 'os'), ('de', 'os', 'fi√©is'), ('os', 'fi√©is', 'de'), ('fi√©is', 'de', 'a'), ('de', 'a', 'casa'), ('a', 'casa', ','), ('casa', ',', 'que'), (',', 'que', 'de'), ('que', 'de', 'ela'), ('de', 'ela', 'esperam'), ('ela', 'esperam', 'a'), ('esperam', 'a', 'm√∫sica'), ('a', 'm√∫sica', '¬´'), ('m√∫sica', '¬´', 'geracionista'), ('¬´', 'geracionista', 'de'), ('geracionista', 'de', 'os'), ('de', 'os', '60'), ('os', '60', 'ou'), ('60', 'ou', 'de'), ('ou', 'de', 'os'), ('de', 'os', '70'), ('os', '70', '.')]\n",
            "\n",
            "üîπ N-gramas de 5 palabras:\n",
            "[('√©', 'um_pouco', 'a', 'vers√£o', 'de'), ('um_pouco', 'a', 'vers√£o', 'de', 'uma'), ('a', 'vers√£o', 'de', 'uma', 'esp√©cie'), ('vers√£o', 'de', 'uma', 'esp√©cie', 'de'), ('de', 'uma', 'esp√©cie', 'de', '¬´'), ('uma', 'esp√©cie', 'de', '¬´', 'outro'), ('esp√©cie', 'de', '¬´', 'outro', 'lado'), ('de', '¬´', 'outro', 'lado', 'de'), ('¬´', 'outro', 'lado', 'de', 'a'), ('outro', 'lado', 'de', 'a', 'noite'), ('lado', 'de', 'a', 'noite', ','), ('de', 'a', 'noite', ',', 'a'), ('a', 'noite', ',', 'a', 'meio'), ('noite', ',', 'a', 'meio', 'caminho'), (',', 'a', 'meio', 'caminho', 'entre'), ('a', 'meio', 'caminho', 'entre', 'os'), ('meio', 'caminho', 'entre', 'os', 'devaneios'), ('caminho', 'entre', 'os', 'devaneios', 'de'), ('entre', 'os', 'devaneios', 'de', 'uma'), ('os', 'devaneios', 'de', 'uma', 'fauna'), ('devaneios', 'de', 'uma', 'fauna', 'perif√©rica'), ('de', 'uma', 'fauna', 'perif√©rica', ','), ('uma', 'fauna', 'perif√©rica', ',', 'seja'), ('fauna', 'perif√©rica', ',', 'seja', 'de'), ('perif√©rica', ',', 'seja', 'de', 'lisboa'), (',', 'seja', 'de', 'lisboa', ','), ('seja', 'de', 'lisboa', ',', 'londres'), ('de', 'lisboa', ',', 'londres', ','), ('lisboa', ',', 'londres', ',', 'dublin'), (',', 'londres', ',', 'dublin', 'ou'), ('londres', ',', 'dublin', 'ou', 'faro'), (',', 'dublin', 'ou', 'faro', 'e'), ('dublin', 'ou', 'faro', 'e', 'portim√£o'), ('ou', 'faro', 'e', 'portim√£o', ','), ('faro', 'e', 'portim√£o', ',', 'e'), ('e', 'portim√£o', ',', 'e', 'a'), ('portim√£o', ',', 'e', 'a', 'postura'), (',', 'e', 'a', 'postura', 'circunspecta'), ('e', 'a', 'postura', 'circunspecta', 'de'), ('a', 'postura', 'circunspecta', 'de', 'os'), ('postura', 'circunspecta', 'de', 'os', 'fi√©is'), ('circunspecta', 'de', 'os', 'fi√©is', 'de'), ('de', 'os', 'fi√©is', 'de', 'a'), ('os', 'fi√©is', 'de', 'a', 'casa'), ('fi√©is', 'de', 'a', 'casa', ','), ('de', 'a', 'casa', ',', 'que'), ('a', 'casa', ',', 'que', 'de'), ('casa', ',', 'que', 'de', 'ela'), (',', 'que', 'de', 'ela', 'esperam'), ('que', 'de', 'ela', 'esperam', 'a'), ('de', 'ela', 'esperam', 'a', 'm√∫sica'), ('ela', 'esperam', 'a', 'm√∫sica', '¬´'), ('esperam', 'a', 'm√∫sica', '¬´', 'geracionista'), ('a', 'm√∫sica', '¬´', 'geracionista', 'de'), ('m√∫sica', '¬´', 'geracionista', 'de', 'os'), ('¬´', 'geracionista', 'de', 'os', '60'), ('geracionista', 'de', 'os', '60', 'ou'), ('de', 'os', '60', 'ou', 'de'), ('os', '60', 'ou', 'de', 'os'), ('60', 'ou', 'de', 'os', '70'), ('ou', 'de', 'os', '70', '.')]\n",
            "\n",
            "üîπ Todos los n-gramas hasta tama√±o 3:\n",
            "[('√©',), ('√©', 'um_pouco'), ('√©', 'um_pouco', 'a'), ('um_pouco',), ('um_pouco', 'a'), ('um_pouco', 'a', 'vers√£o'), ('a',), ('a', 'vers√£o'), ('a', 'vers√£o', 'de'), ('vers√£o',), ('vers√£o', 'de'), ('vers√£o', 'de', 'uma'), ('de',), ('de', 'uma'), ('de', 'uma', 'esp√©cie'), ('uma',), ('uma', 'esp√©cie'), ('uma', 'esp√©cie', 'de'), ('esp√©cie',), ('esp√©cie', 'de'), ('esp√©cie', 'de', '¬´'), ('de',), ('de', '¬´'), ('de', '¬´', 'outro'), ('¬´',), ('¬´', 'outro'), ('¬´', 'outro', 'lado'), ('outro',), ('outro', 'lado'), ('outro', 'lado', 'de'), ('lado',), ('lado', 'de'), ('lado', 'de', 'a'), ('de',), ('de', 'a'), ('de', 'a', 'noite'), ('a',), ('a', 'noite'), ('a', 'noite', ','), ('noite',), ('noite', ','), ('noite', ',', 'a'), (',',), (',', 'a'), (',', 'a', 'meio'), ('a',), ('a', 'meio'), ('a', 'meio', 'caminho'), ('meio',), ('meio', 'caminho'), ('meio', 'caminho', 'entre'), ('caminho',), ('caminho', 'entre'), ('caminho', 'entre', 'os'), ('entre',), ('entre', 'os'), ('entre', 'os', 'devaneios'), ('os',), ('os', 'devaneios'), ('os', 'devaneios', 'de'), ('devaneios',), ('devaneios', 'de'), ('devaneios', 'de', 'uma'), ('de',), ('de', 'uma'), ('de', 'uma', 'fauna'), ('uma',), ('uma', 'fauna'), ('uma', 'fauna', 'perif√©rica'), ('fauna',), ('fauna', 'perif√©rica'), ('fauna', 'perif√©rica', ','), ('perif√©rica',), ('perif√©rica', ','), ('perif√©rica', ',', 'seja'), (',',), (',', 'seja'), (',', 'seja', 'de'), ('seja',), ('seja', 'de'), ('seja', 'de', 'lisboa'), ('de',), ('de', 'lisboa'), ('de', 'lisboa', ','), ('lisboa',), ('lisboa', ','), ('lisboa', ',', 'londres'), (',',), (',', 'londres'), (',', 'londres', ','), ('londres',), ('londres', ','), ('londres', ',', 'dublin'), (',',), (',', 'dublin'), (',', 'dublin', 'ou'), ('dublin',), ('dublin', 'ou'), ('dublin', 'ou', 'faro'), ('ou',), ('ou', 'faro'), ('ou', 'faro', 'e'), ('faro',), ('faro', 'e'), ('faro', 'e', 'portim√£o'), ('e',), ('e', 'portim√£o'), ('e', 'portim√£o', ','), ('portim√£o',), ('portim√£o', ','), ('portim√£o', ',', 'e'), (',',), (',', 'e'), (',', 'e', 'a'), ('e',), ('e', 'a'), ('e', 'a', 'postura'), ('a',), ('a', 'postura'), ('a', 'postura', 'circunspecta'), ('postura',), ('postura', 'circunspecta'), ('postura', 'circunspecta', 'de'), ('circunspecta',), ('circunspecta', 'de'), ('circunspecta', 'de', 'os'), ('de',), ('de', 'os'), ('de', 'os', 'fi√©is'), ('os',), ('os', 'fi√©is'), ('os', 'fi√©is', 'de'), ('fi√©is',), ('fi√©is', 'de'), ('fi√©is', 'de', 'a'), ('de',), ('de', 'a'), ('de', 'a', 'casa'), ('a',), ('a', 'casa'), ('a', 'casa', ','), ('casa',), ('casa', ','), ('casa', ',', 'que'), (',',), (',', 'que'), (',', 'que', 'de'), ('que',), ('que', 'de'), ('que', 'de', 'ela'), ('de',), ('de', 'ela'), ('de', 'ela', 'esperam'), ('ela',), ('ela', 'esperam'), ('ela', 'esperam', 'a'), ('esperam',), ('esperam', 'a'), ('esperam', 'a', 'm√∫sica'), ('a',), ('a', 'm√∫sica'), ('a', 'm√∫sica', '¬´'), ('m√∫sica',), ('m√∫sica', '¬´'), ('m√∫sica', '¬´', 'geracionista'), ('¬´',), ('¬´', 'geracionista'), ('¬´', 'geracionista', 'de'), ('geracionista',), ('geracionista', 'de'), ('geracionista', 'de', 'os'), ('de',), ('de', 'os'), ('de', 'os', '60'), ('os',), ('os', '60'), ('os', '60', 'ou'), ('60',), ('60', 'ou'), ('60', 'ou', 'de'), ('ou',), ('ou', 'de'), ('ou', 'de', 'os'), ('de',), ('de', 'os'), ('de', 'os', '70'), ('os',), ('os', '70'), ('os', '70', '.'), ('70',), ('70', '.'), ('.',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Apartado 1.2 ‚Äî Exemplo 1.2: Distribui√ß√£o de frequ√™ncias\n",
        "\n",
        "üìò Objetivo:\n",
        "Calcular cu√°ntas veces aparece cada n-grama en un texto o corpus y mostrar los m√°s frecuentes."
      ],
      "metadata": {
        "id": "0a4m6P2xXqlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Apartado 1.2: Exemplo 1.2\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Frase de ejemplo\n",
        "proverbio = \"\"\"\n",
        "O tempo perguntou ao tempo quanto tempo o tempo tem;\n",
        "o tempo respondeu ao tempo que o tempo tem tanto tempo quanto tempo o tempo tem.\n",
        "\"\"\"\n",
        "\n",
        "# Import necessary functions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Tokenizar la frase y pasar todo a min√∫sculas\n",
        "tokens = word_tokenize(proverbio.lower())\n",
        "\n",
        "# Generar bigramas\n",
        "bigrams_list = list(nltk.bigrams(tokens))\n",
        "\n",
        "# Calcular la distribuci√≥n de frecuencias\n",
        "ngram_fdist = FreqDist(bigrams_list)\n",
        "\n",
        "# Mostrar los 10 bigramas m√°s frecuentes\n",
        "print(\"üîπ Bigramas m√°s frecuentes:\")\n",
        "for bigrama, freq in ngram_fdist.most_common(10):\n",
        "    print(f\"{bigrama}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R8QrmkXXxvJ",
        "outputId": "6b927039-fb11-434f-e74c-d5bd31c497c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Bigramas m√°s frecuentes:\n",
            "('o', 'tempo'): 5\n",
            "('tempo', 'tem'): 3\n",
            "('ao', 'tempo'): 2\n",
            "('tempo', 'quanto'): 2\n",
            "('quanto', 'tempo'): 2\n",
            "('tempo', 'o'): 2\n",
            "('tempo', 'perguntou'): 1\n",
            "('perguntou', 'ao'): 1\n",
            "('tem', ';'): 1\n",
            "(';', 'o'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Exerc√≠cio 1.1 ‚Äî N-gramas mais frequentes\n",
        "\n",
        "üìò Enunciado resumido:\n",
        "\n",
        "Crea una funci√≥n que reciba una lista de frases (por ejemplo, del corpus floresta) y devuelva los m n-gramas m√°s frecuentes, dentro de un intervalo de n que elijas.\n",
        "\n",
        "üí° Adem√°s, el enunciado sugiere usar el m√©todo update() de FreqDist para ir actualizando las frecuencias de varios tama√±os de n-gramas."
      ],
      "metadata": {
        "id": "oLvqM9jDYzXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exerc√≠cio 1.1\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk import everygrams, FreqDist\n",
        "\n",
        "# Cargar frases y pasarlas a min√∫sculas\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "def ngramas_mas_frecuentes(sentences, min_n=2, max_n=3, m=10):\n",
        "    \"\"\"\n",
        "    Calcula los m n-gramas m√°s frecuentes en una lista de frases.\n",
        "\n",
        "    Par√°metros:\n",
        "    - sentences: lista de frases tokenizadas.\n",
        "    - min_n, max_n: intervalo del tama√±o de los n-gramas (por defecto 2 a 3).\n",
        "    - m: n√∫mero de n-gramas m√°s frecuentes a mostrar.\n",
        "    \"\"\"\n",
        "    fdist = FreqDist()\n",
        "\n",
        "    # Recorremos cada frase\n",
        "    for sent in sentences:\n",
        "        # Generar todos los n-gramas entre min_n y max_n\n",
        "        ngram_list = everygrams(sent, min_len=min_n, max_len=max_n)\n",
        "        # Actualizar el contador de frecuencias\n",
        "        fdist.update(ngram_list)\n",
        "\n",
        "    # Mostrar los m m√°s comunes\n",
        "    print(f\"üîπ {m} n-gramas m√°s frecuentes (entre {min_n} y {max_n}):\")\n",
        "    for ngram, freq in fdist.most_common(m):\n",
        "        print(f\"{ngram}: {freq}\")\n",
        "\n",
        "    return fdist.most_common(m)\n",
        "\n",
        "# Ejecutar funci√≥n con los par√°metros por defecto\n",
        "ngramas_mas_frecuentes(lowered_sents, min_n=2, max_n=3, m=10)\n",
        "\n",
        "\n",
        "# FALTAR√çA CREAR OTRA FUNCION QUE ELIMINE STOPWORDS Y ACENTUACIONES (una frase foto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTZCIsROY0VV",
        "outputId": "d9ad3961-fb48-445e-cd4e-4db75de17b81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ 10 n-gramas m√°s frecuentes (entre 2 y 3):\n",
            "('de', 'o'): 2876\n",
            "('de', 'a'): 2567\n",
            "('em', 'o'): 1511\n",
            "('em', 'a'): 1402\n",
            "('de', 'os'): 1003\n",
            "(',', 'em'): 826\n",
            "('¬ª', ','): 758\n",
            "(',', 'a'): 745\n",
            "('a', 'o'): 742\n",
            "(',', 'que'): 676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('de', 'o'), 2876),\n",
              " (('de', 'a'), 2567),\n",
              " (('em', 'o'), 1511),\n",
              " (('em', 'a'), 1402),\n",
              " (('de', 'os'), 1003),\n",
              " ((',', 'em'), 826),\n",
              " (('¬ª', ','), 758),\n",
              " ((',', 'a'), 745),\n",
              " (('a', 'o'), 742),\n",
              " ((',', 'que'), 676)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Exemplo 1.3 ‚Äî Marcando el in√≠cio e o fim das frases\n",
        "\n",
        "üìò Objetivo:\n",
        "Aprender a preparar los datos para entrenar modelos de lenguaje, a√±adiendo marcadores de inicio (<s>) y fin (</s>) a cada frase."
      ],
      "metadata": {
        "id": "mScSuvkKaJp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† ¬øPor qu√© se hace esto?\n",
        "\n",
        "Cuando entrenamos modelos de lenguaje (por ejemplo, de bigramas o trigramas), queremos que el modelo entienda cu√°ndo empieza y cu√°ndo termina una frase.\n",
        "As√≠ puede aprender cosas como:\n",
        "\n",
        "Qu√© palabras suelen comenzar una oraci√≥n.\n",
        "\n",
        "Qu√© palabras suelen aparecer al final.\n",
        "\n",
        "IMPORTANTE: pero todo esto esta relacionado con los diagramas, para que no se invente n-gramas cambiandole el orden a las palabras porque sabe que las que lleven \"s\" es porque es la palabra de inicio y no puede ir en el medio ni en el final"
      ],
      "metadata": {
        "id": "0IHahCW4am6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.3\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
        "\n",
        "# Asegurar que el corpus est√© descargado\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Cargar y preparar las frases\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# Ejemplo con una frase concreta\n",
        "tokens = lowered_sents[0]\n",
        "\n",
        "# üîπ A√±adir marcadores de inicio y fin manualmente\n",
        "padded_tokens = list(pad_both_ends(tokens, n=2))\n",
        "print(\"üî∏ Tokens con padding:\")\n",
        "print(padded_tokens)\n",
        "\n",
        "# üîπ Generar bigramas a partir de la frase con padding\n",
        "padded_bigrams = list(nltk.bigrams(padded_tokens))\n",
        "print(\"\\nüî∏ Bigramas con padding:\")\n",
        "print(padded_bigrams)\n",
        "\n",
        "# üîπ Alternativa: hacer lo mismo para todas las frases del corpus\n",
        "data, vocab = padded_everygram_pipeline(2, lowered_sents)\n",
        "vocab = list(vocab)\n",
        "\n",
        "print(\"\\nüî∏ Ejemplo de n-gramas generados:\")\n",
        "for sent in data:\n",
        "    for ngram in sent:\n",
        "        print(ngram)\n",
        "    break  # mostramos solo la primera frase\n",
        "\n",
        "print(\"\\nüî∏ Vocabulario (primeras 50 palabras):\")\n",
        "print(vocab[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3DHtaFgauF0",
        "outputId": "3c720944-f281-467c-edcf-772f9bfd94a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî∏ Tokens con padding:\n",
            "['<s>', 'um', 'revivalismo', 'refrescante', '</s>']\n",
            "\n",
            "üî∏ Bigramas con padding:\n",
            "[('<s>', 'um'), ('um', 'revivalismo'), ('revivalismo', 'refrescante'), ('refrescante', '</s>')]\n",
            "\n",
            "üî∏ Ejemplo de n-gramas generados:\n",
            "('<s>',)\n",
            "('<s>', 'um')\n",
            "('um',)\n",
            "('um', 'revivalismo')\n",
            "('revivalismo',)\n",
            "('revivalismo', 'refrescante')\n",
            "('refrescante',)\n",
            "('refrescante', '</s>')\n",
            "('</s>',)\n",
            "\n",
            "üî∏ Vocabulario (primeras 50 palabras):\n",
            "['<s>', 'um', 'revivalismo', 'refrescante', '</s>', '<s>', 'o', '7_e_meio', '√©', 'um', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.', '</s>', '<s>', '√©', 'uma', 'de', 'as', 'mais', 'antigas', 'discotecas', 'de', 'o', 'algarve', ',', 'situada', 'em', 'albufeira', ',', 'que', 'continua', 'a', 'manter', 'os', 'tra√ßos', 'decorativos', 'e', 'as', 'clientelas', 'de', 'sempre', '.', '</s>', '<s>', '√©', 'um_pouco']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîÆ C√≥mo ayuda en la pr√°ctica\n",
        "\n",
        "1Ô∏è‚É£ En entrenamiento de modelos de lenguaje\n",
        "Cuando entrenas un modelo (por ejemplo, MLE(2) de NLTK), el padding permite calcular probabilidades como:\n",
        "\n",
        "P(\"o\" | \"s\") ‚Üí qu√© palabra suele venir al comienzo.\n",
        "P(\"/s\" | \"tempo\") ‚Üí qu√© palabra suele venir al final.\n",
        "\n",
        "2Ô∏è‚É£ En generaci√≥n de texto\n",
        "Cuando generas nuevas frases, el modelo empieza desde s y sigue eligiendo palabras hasta que llega a /s.\n",
        "As√≠ sabe d√≥nde empezar y d√≥nde detenerse.\n",
        "\n",
        "3Ô∏è‚É£ En evaluaci√≥n del modelo (perplejidad)\n",
        "Durante la evaluaci√≥n con frases de prueba, tambi√©n se usan los marcadores para mantener la coherencia del c√°lculo de probabilidad total de una oraci√≥n."
      ],
      "metadata": {
        "id": "HFg1PlUvc4cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Exemplo 1.4 ‚Äî Treinar um modelo de bi-gramas (MLE)\n",
        "\n",
        "üìò Objetivo:\n",
        "Aprender a entrenar un modelo de lenguaje de n-gramas utilizando la clase MLE (Maximum Likelihood Estimator) de la biblioteca NLTK.\n",
        "\n",
        "üß† Qu√© es un modelo de lenguaje basado en n-gramas\n",
        "\n",
        "Un modelo de lenguaje intenta predecir la siguiente palabra a partir de las anteriores.\n",
        "En un modelo de bigramas (n = 2), se calcula la probabilidad de cada palabra seg√∫n la anterior:"
      ],
      "metadata": {
        "id": "dmBMfIT_dJlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "P(w_i \\mid w_{i-1}) = \\frac{C(w_{i-1}, w_i)}{C(w_{i-1})}\n",
        "$$\n",
        "\n",
        "donde:  \n",
        "\n",
        "- \\( C(w_{i-1}, w_i) \\) = cu√°ntas veces aparece el bigrama  \n",
        "- \\( C(w_{i-1}) \\) = cu√°ntas veces aparece la primera palabra del bigrama\n"
      ],
      "metadata": {
        "id": "a4zNioEUeSiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.4\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar corpus\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Cargar frases y convertirlas a min√∫sculas\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# üîπ Preparar datos con padding y obtener vocabulario\n",
        "n = 2  # modelo de bigramas\n",
        "train_data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "# üîπ Crear el modelo MLE (Maximum Likelihood Estimation)\n",
        "lm = MLE(n)\n",
        "\n",
        "# üîπ Entrenar el modelo con los datos\n",
        "lm.fit(train_data, vocab)\n",
        "\n",
        "# üîπ Mostrar tama√±o del vocabulario aprendido\n",
        "print(\"üîπ Tama√±o del vocabulario:\", len(lm.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsSes7-PdouF",
        "outputId": "094b522d-97e3-4852-c420-28a54ebbb6ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Tama√±o del vocabulario: 27717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCLUSION: Para entender como funciona realmente el padding en los n-gramas y usa el modelo el MLE para predecir la sigueinte palabra.\n",
        "# üîç Qu√© hace internamente el modelo\n",
        "  # Aprende cu√°ntas veces aparece cada bigrama en el corpus.\n",
        "  # Calcula la probabilidad condicional de una palabra dada la anterior.\n",
        "  # Usa <s> y </s> para entender los l√≠mites de frases."
      ],
      "metadata": {
        "id": "4vi46o1Kd8X6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Exemplo 1.5 ‚Äî Consultar el modelo MLE"
      ],
      "metadata": {
        "id": "DqUuXTakePUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò Objetivo:\n",
        "Aprender a:\n",
        "\n",
        "Buscar palabras o secuencias dentro del vocabulario del modelo.\n",
        "\n",
        "Consultar cu√°ntas veces aparecen ciertos bigramas.\n",
        "\n",
        "Calcular probabilidades seg√∫n el modelo entrenado."
      ],
      "metadata": {
        "id": "OpizDwMyednI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Conceptos importantes\n",
        "\n",
        "1Ô∏è‚É£ Vocabulario del modelo (lm.vocab)\n",
        "Incluye todas las palabras que el modelo ha visto durante el entrenamiento.\n",
        "Las palabras no vistas se representan con el s√≠mbolo <UNK> (unknown token).\n",
        "\n",
        "2Ô∏è‚É£ Conteos (lm.counts)\n",
        "El modelo almacena las frecuencias de todos los unigramas, bigramas, etc.\n",
        "Puedes acceder a ellas como si fuera un diccionario anidado:\n",
        "\n",
        "lm.counts['palabra']              # cu√°ntas veces aparece la palabra\n",
        "lm.counts[['palabra']]['otra']    # cu√°ntas veces aparece ('palabra', 'otra')\n",
        "\n",
        "\n",
        "3Ô∏è‚É£ Probabilidades (lm.score())\n",
        "Calcula la probabilidad condicional de una palabra dada el contexto previo:\n",
        "\n",
        "lm.score('dia', ['de'])  # P('dia' | 'de')"
      ],
      "metadata": {
        "id": "0auXrjYaey4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.5\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar corpus\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Preparar corpus\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# Preparar datos y vocabulario (bigramas)\n",
        "n = 2\n",
        "data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "# Entrenar el modelo\n",
        "lm = MLE(n)\n",
        "lm.fit(data, vocab)\n",
        "\n",
        "# üîπ Consultar el vocabulario\n",
        "print(\"üîπ Vocabulario (primeras 20 palabras):\")\n",
        "print(list(lm.vocab)[:20])\n",
        "\n",
        "# üîπ Buscar secuencias en el modelo\n",
        "print(\"\\nüîπ Lookup de frases conocidas y desconocidas:\")\n",
        "print(lm.vocab.lookup(lowered_sents[0]))\n",
        "print(lm.vocab.lookup(['isto', '√©', 'um', 'teste']))\n",
        "print(lm.vocab.lookup(['uma', 'esp√©cie', 'de', 'blah']))\n",
        "\n",
        "# üîπ Consultar contajes (frecuencias)\n",
        "print(\"\\nüîπ Conteos:\")\n",
        "print(\"C('dois') =\", lm.counts['dois'])\n",
        "print(\"C('dois', 'anos') =\", lm.counts[['dois']]['anos'])\n",
        "print(\"C('dois', 'dias') =\", lm.counts[['dois']]['dias'])\n",
        "\n",
        "# üîπ Consultar probabilidades\n",
        "print(\"\\nüîπ Probabilidades seg√∫n el modelo:\")\n",
        "print(\"P('noite') =\", lm.score('noite'))\n",
        "print(\"P('dia' | 'de') =\", lm.score('dia', ['de']))      # la prob de aparecer dia despues de \"de\"\n",
        "print(\"P('de' | 'tarde') =\", lm.score('de', ['tarde']))\n",
        "print(\"P('de' | 'noite') =\", lm.score('de', ['noite']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP2RVCXJe7AB",
        "outputId": "a9545e80-db14-4cf1-e558-d536966bd3d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Vocabulario (primeras 20 palabras):\n",
            "['<s>', 'um', 'revivalismo', 'refrescante', '</s>', 'o', '7_e_meio', '√©', 'ex-libris', 'de', 'a', 'noite', 'algarvia', '.', 'uma', 'as', 'mais', 'antigas', 'discotecas', 'algarve']\n",
            "\n",
            "üîπ Lookup de frases conocidas y desconocidas:\n",
            "('um', 'revivalismo', 'refrescante')\n",
            "('isto', '√©', 'um', 'teste')\n",
            "('uma', 'esp√©cie', 'de', '<UNK>')\n",
            "\n",
            "üîπ Conteos:\n",
            "C('dois') = 231\n",
            "C('dois', 'anos') = 14\n",
            "C('dois', 'dias') = 12\n",
            "\n",
            "üîπ Probabilidades seg√∫n el modelo:\n",
            "P('noite') = 0.0002647753316202514\n",
            "P('dia' | 'de') = 0.00013630477748245075\n",
            "P('de' | 'tarde') = 0.18518518518518517\n",
            "P('de' | 'noite') = 0.2786885245901639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Exemplo 1.6 ‚Äî Gera√ß√£o de texto com o modelo MLE"
      ],
      "metadata": {
        "id": "7OE5WM8gI_86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìò Objetivo:\n",
        "Usar el modelo de lenguaje entrenado (en el Exemplo 1.4) para generar secuencias de palabras nuevas que imiten el estilo del corpus."
      ],
      "metadata": {
        "id": "OgC-Iq_lI8mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# Ficha 4 - N-gramas | Exemplo 1.6\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar corpus\n",
        "nltk.download('floresta')\n",
        "\n",
        "# Preparar corpus\n",
        "sents = floresta.sents()\n",
        "lowered_sents = [[w.lower() for w in s] for s in sents]\n",
        "\n",
        "# Preparar datos (bigramas)\n",
        "n = 2\n",
        "train_data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "# Entrenar modelo de bigramas\n",
        "lm = MLE(n)\n",
        "lm.fit(train_data, vocab)\n",
        "\n",
        "# üîπ Generar una secuencia de 7 palabras\n",
        "print(\"üîπ Frase generada por el modelo:\\n\")\n",
        "print(lm.generate(7, random_seed=3))"
      ],
      "metadata": {
        "id": "pSYgnsY6JMO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c3e148-e73e-4a11-8429-65857f3629cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Frase generada por el modelo:\n",
            "\n",
            "['a', 'morte', 'de', 'o', 'paulistano', 'n√£o', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Objetivo del Ejercicio 1.2"
      ],
      "metadata": {
        "id": "-EhnN0uVvWhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "‚ÄúExperimente treinar modelos de n-gramas de diferentes tamanhos, com diferentes corpos, para depois gerar sequ√™ncias com eles.‚Äù\n",
        "\n",
        "En otras palabras, debemos:\n",
        "\n",
        "Entrenar modelos de lenguaje basados en n-gramas (por ejemplo, unigramas, bigramas, trigramas).\n",
        "\n",
        "Probarlos con diferentes corpus (como floresta o mac_morpho del NLTK).\n",
        "\n",
        "Generar secuencias de texto con cada modelo para observar c√≥mo cambia el resultado seg√∫n el tama√±o de los n-gramas y el corpus usado."
      ],
      "metadata": {
        "id": "OKyMYOJPvdg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Ejercicio 1.2 - Modelos de N-gramas\n",
        "# ==============================\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import floresta, mac_morpho\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "# Asegurar que los corpus est√©n descargados\n",
        "nltk.download('floresta')\n",
        "nltk.download('mac_morpho')\n",
        "\n",
        "# Selecci√≥n de corpus\n",
        "corpora = {\n",
        "    'floresta': floresta.sents(),\n",
        "    'mac_morpho': mac_morpho.sents()\n",
        "}\n",
        "\n",
        "# Funci√≥n para entrenar modelo y generar texto\n",
        "def treinar_e_gerar(corpus, n=2, num_palavras=10):\n",
        "    # Convertir todas las palabras a min√∫sculas\n",
        "    lowered_sents = [[w.lower() for w in s] for s in corpus]\n",
        "\n",
        "    # Preparar datos y vocabulario\n",
        "    train_data, vocab = padded_everygram_pipeline(n, lowered_sents)\n",
        "\n",
        "    # Entrenar modelo MLE\n",
        "    model = MLE(n)\n",
        "    model.fit(train_data, vocab)\n",
        "\n",
        "    # Generar texto\n",
        "    print(f\"\\n=== Modelo {n}-gramas ({len(model.vocab)} palabras no repetidas) ===\")\n",
        "    print(\"Texto generado:\")\n",
        "    print(' '.join(model.generate(num_palavras, random_seed=3)))\n",
        "\n",
        "# Entrenar modelos con diferentes corpus y tama√±os de n-gramas\n",
        "for nome_corpus, corpus in corpora.items():\n",
        "    print(f\"\\n\\n--- Corpus: {nome_corpus.upper()} ---\")\n",
        "    for n in [2, 3, 4]:\n",
        "        treinar_e_gerar(corpus, n=n, num_palavras=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_bA2bEnvesu",
        "outputId": "2688ac46-a955-4d35-b7b8-e353a1d3154a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]   Package floresta is already up-to-date!\n",
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Package mac_morpho is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Corpus: FLORESTA ---\n",
            "\n",
            "=== Modelo 2-gramas (27717 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "a morte de o paulistano n√£o ? </s> afirmou a √≥scar_monteiro_torres ,\n",
            "\n",
            "=== Modelo 3-gramas (27717 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> a fam√≠lia durante o almo√ßo de trabalho . </s> </s> </s>\n",
            "\n",
            "=== Modelo 4-gramas (27717 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> <s> <s> o papa jo√£o_paulo_2¬∫ escolheu a irm√£ em√≠lia_ehrlich para ocupar\n",
            "\n",
            "\n",
            "--- Corpus: MAC_MORPHO ---\n",
            "\n",
            "=== Modelo 2-gramas (59914 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "a mesma equipe econ√¥mica e 80 % em a copa √© menor\n",
            "\n",
            "=== Modelo 3-gramas (59914 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> a fl√≥rida </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "\n",
            "=== Modelo 4-gramas (59914 palabras no repetidas) ===\n",
            "Texto generado:\n",
            "<s> <s> <s> museu de arte contempor√¢nea re√∫ne 112 destacados artistas de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Objetivo del Ejercicio 1.3"
      ],
      "metadata": {
        "id": "zxFTUpP7xf5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "‚ÄúCrie uma fun√ß√£o para, a partir da lista de tokens geradas, que pode ainda incluir os s√≠mbolos <s> e </s>, crie uma √∫nica string. Pode ignorar os <s> e parar nos </s>, e tamb√©m pode usar a fun√ß√£o detokenize() da classe TreebankWordDetokenizer.‚Äù\n",
        "\n",
        "En este ejercicio debemos reconstruir una frase completa (string) a partir de una lista de tokens generada por un modelo de lenguaje.\n",
        "Durante la generaci√≥n del texto, el modelo incluye los s√≠mbolos <s> (inicio de frase) y </s> (fin de frase).\n",
        "El objetivo es eliminar esos marcadores y unir los tokens en una frase limpia."
      ],
      "metadata": {
        "id": "vbP1b8L4xhnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Ejercicio 1.3 - Detokenizaci√≥n de secuencias\n",
        "# ==============================\n",
        "\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "def reconstruir_frase(tokens):\n",
        "    \"\"\"\n",
        "    Recibe una lista de tokens posiblemente con <s> y </s>,\n",
        "    ignora esos s√≠mbolos y devuelve una √∫nica string limpia.\n",
        "    \"\"\"\n",
        "    frase_tokens = []\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        elif token == '</s>':\n",
        "            break\n",
        "        frase_tokens.append(token)\n",
        "\n",
        "    # Usar TreebankWordDetokenizer para recomponer la frase\n",
        "    detok = TreebankWordDetokenizer().detokenize(frase_tokens)\n",
        "    return detok\n",
        "\n",
        "# Ejemplo de uso:\n",
        "tokens_gerados = ['<s>', 'o', 'tempo', 'voa', 'r√°pido', '</s>']\n",
        "frase = reconstruir_frase(tokens_gerados)\n",
        "print(\"Tokens:\", tokens_gerados)\n",
        "print(\"Frase reconstruida:\", frase)\n"
      ],
      "metadata": {
        "id": "FSntViX1wtha",
        "outputId": "84c9551d-8d6a-4a92-d727-7ce5cf040317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['<s>', 'o', 'tempo', 'voa', 'r√°pido', '</s>']\n",
            "Frase reconstruida: o tempo voa r√°pido\n"
          ]
        }
      ]
    }
  ]
}